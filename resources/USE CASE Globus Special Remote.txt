WORKING WITH GLOBUS AS A SPECIAL REMOTE:


USE CASE 1:

Admin side:

As an Admin user of datalad for NeuroHub/CONP, I would like to popupate datalad with various datasets generated by scientific research around the world. Therefore researchers can get such datasets available via datalad, work and build on them. Among the many existing platforms supporting finding and sharing research data, FRDR (https://www.frdr.ca/repo/?locale=en) is a rich and commonly used one. It makes datasets available to the public using Globus (https://www.computecanada.ca/research-portal/national-services/globus-portal/), a service for big data transfer and sharing that facilitates research work by connecting computing resources and making big data portable. 

In the process of setting and adding a new dataset to datalad, which is built on git-annex, very large files get referenced and stored as symlinks by git annex. Therefore users who will install the new dataset via datalad will not end up having actual large files data readly available in their filesystem to use: to do that they will have to download those files. So, where will large files content actually be stored? We opted to involve Globus for this purpose and allow a 'under the layer' communication between git annex (storing symlinks) and Globus (providing actual content) for users to download data from there. Few considerations need to be made at this point. 1 - At the current implementation stage, a dataset available via Globus is READ-ONLY, hence files can be downloaded but not uploaded or removed. This is purly a way for users to get access to data they need and to git annex and datalad functionalities as well. Each dataset will release a set of metadata that will be managed by datalad. 2 - A dataset is available and can be downloaded from a Globus 'shared endpoint' that was originally set up by relative dataset owners/researchers, therefore we only hook to that location but we do not manage it in the first place. 

It is possible to add further implementations to the current system if needed!


User side:

I am a researcher who would like to build on existing work to conduct my experiments. I use datalad to install existing datasets on my machine but would like to download some of the files. Therefore, I follow the procedure for downloading this particular dataset and I initialize a Globus special remote. I log in to Globus via ORCHID credentials and I set up my hook as explaied in the docs. I can now simply run 'datalad get path/to/file' to download the file I need from Globus.



